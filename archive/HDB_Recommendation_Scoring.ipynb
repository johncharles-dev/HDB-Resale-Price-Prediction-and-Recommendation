{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41269995",
   "metadata": {},
   "source": [
    "# HDB Recommendation System - Scoring Implementation\n",
    "\n",
    "This notebook implements the scoring logic for the HDB flat recommendation system described in Section 5.\n",
    "\n",
    "## ðŸ“‹ Overview\n",
    "\n",
    "The recommendation system uses **content-based filtering with multi-criteria scoring** to rank HDB flats based on user preferences. It combines 5 independent scores with predefined weights to generate personalized recommendations.\n",
    "\n",
    "## ðŸ”„ Processing Pipeline\n",
    "\n",
    "1. **Hard Filtering** â†’ Reduce 254K flats to candidates matching essential criteria (budget, type, location)\n",
    "2. **XGBoost Prediction** â†’ Predict fair market value for all candidates\n",
    "3. **Score Calculation** â†’ Compute 5 independent scores for each candidate\n",
    "4. **Weighted Ranking** â†’ Combine scores using fixed weights (35% travel, 25% value, 20% budget, 15% amenity, 5% space)\n",
    "5. **Top-N Selection** â†’ Return top 10 recommendations with explanations\n",
    "\n",
    "## ðŸŽ¯ Scoring Components\n",
    "\n",
    "| Score | Weight | Purpose | Range |\n",
    "|-------|--------|---------|-------|\n",
    "| **Travel Convenience** | 35% | Weighted distance to work/frequent destinations | 0-100 |\n",
    "| **Value Efficiency** | 25% | Predicted price per sqm (space efficiency) | 0-100 |\n",
    "| **Budget Comfort** | 20% | How comfortably price fits within budget | 0-100 |\n",
    "| **Amenity Access** | 15% | Proximity to MRT, schools, malls, hawkers | 0-100 |\n",
    "| **Space Adequacy** | 5% | Alignment with desired floor area | 0-100 |\n",
    "\n",
    "**Final Score Formula:**\n",
    "```\n",
    "final_score = 0.35Ã—travel + 0.25Ã—value + 0.20Ã—budget + 0.15Ã—amenity + 0.05Ã—space\n",
    "```\n",
    "\n",
    "## ðŸ“‚ File Requirements\n",
    "\n",
    "Before running, ensure you have:\n",
    "- âœ… `HDB_model_ready.csv` - Main dataset (254K+ flats)\n",
    "- âœ… `town_code_map.csv` - Town name mappings\n",
    "- âœ… `flat_type_int_map.csv` - Flat type mappings\n",
    "- âœ… `flat_model_code_map.csv` - Flat model mappings\n",
    "- âœ… `xgboost_model.pkl` - Trained price prediction model from Section 4\n",
    "\n",
    "## ðŸš€ Quick Start\n",
    "\n",
    "1. Run cells 1-2 to load data and model\n",
    "2. Run cells 3-4 to define helper and scoring functions\n",
    "3. Test with sample input in cell 7\n",
    "4. Copy Flask API code from cell 8 to `app.py` for production\n",
    "\n",
    "## ðŸ”§ Customization Points\n",
    "\n",
    "- **Travel score**: Adjust `frequency_weights` dictionary (cell 4)\n",
    "- **Score weights**: Modify weights in `generate_recommendations()` (cell 6)\n",
    "- **Max distances**: Change `max_distance` thresholds in scoring functions\n",
    "- **Top N**: Set `top_n` parameter when calling `generate_recommendations()`\n",
    "\n",
    "## ðŸ“– For New Users\n",
    "\n",
    "Each function includes:\n",
    "- Detailed docstring explaining purpose and parameters\n",
    "- Inline comments explaining algorithm logic\n",
    "- Example usage with sample inputs/outputs\n",
    "- Edge case handling notes\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DEPENDENCIES\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import json\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATASET\n",
    "# ============================================================================\n",
    "# Load the main HDB dataset with 254K+ flat records\n",
    "# This contains all historical resale transactions with features engineered in Section 4\n",
    "df = pd.read_csv(r'HDB Clone/HDB-Resale-Price-Prediction-and-Recommendation-main/Model_Building/HDB_model_ready.csv')\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD MAPPING FILES\n",
    "# ============================================================================\n",
    "# These CSV files map encoded values to human-readable names\n",
    "# town_code_map.csv: Maps town_code (0-25) to town names (e.g., 0 = 'ANG MO KIO')\n",
    "# flat_type_int_map.csv: Maps flat_type_int (1-7) to flat types (e.g., 4 = '4 ROOM')\n",
    "# flat_model_code_map.csv: Maps flat_model_code (0-10) to model names (e.g., 2 = 'Improved')\n",
    "town_map = pd.read_csv(r'HDB Clone/HDB-Resale-Price-Prediction-and-Recommendation-main/Model_Building/mappings_csv/town_code_map.csv')\n",
    "flat_type_map = pd.read_csv(r'HDB Clone/HDB-Resale-Price-Prediction-and-Recommendation-main/Model_Building/mappings_csv/flat_type_int_map.csv')\n",
    "flat_model_map = pd.read_csv(r'HDB Clone/HDB-Resale-Price-Prediction-and-Recommendation-main/Model_Building/mappings_csv/flat_model_code_map.csv')\n",
    "\n",
    "print(f\"Dataset loaded: {len(df)} flats\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbbd49b",
   "metadata": {},
   "source": [
    "## 2. Load Trained XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c148ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD TRAINED ML MODEL\n",
    "# ============================================================================\n",
    "# Load the XGBoost price prediction model trained in Section 4\n",
    "# This model predicts fair market value based on flat features\n",
    "# \n",
    "# TODO: Update 'path/to/your/xgboost_model.pkl' with your actual model file path\n",
    "# Example: 'HDB Clone/.../Model_Building/xgboost_model.pkl'\n",
    "#\n",
    "with open('path/to/your/xgboost_model.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)\n",
    "\n",
    "print(\"XGBoost model loaded successfully\")\n",
    "\n",
    "# ============================================================================\n",
    "# OPTIONAL: Load preprocessing objects if you used them during training\n",
    "# ============================================================================\n",
    "# If you applied StandardScaler, LabelEncoder, or other transformers in Section 4,\n",
    "# load them here to ensure consistent preprocessing\n",
    "#\n",
    "# Example:\n",
    "# with open('path/to/scaler.pkl', 'rb') as f:\n",
    "#     scaler = pickle.load(f)\n",
    "# with open('path/to/label_encoder.pkl', 'rb') as f:\n",
    "#     label_encoder = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47265be2",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTION: Calculate Geographic Distance\n",
    "# ============================================================================\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great-circle distance between two points on Earth using the Haversine formula.\n",
    "    \n",
    "    This function is used to calculate distances from flats to user-specified destinations\n",
    "    (work, school, parents' homes, etc.) for the travel convenience score.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lat1, lon1 : float\n",
    "        Latitude and longitude of the first point (e.g., flat location)\n",
    "    lat2, lon2 : float\n",
    "        Latitude and longitude of the second point (e.g., workplace)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Distance in kilometers\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> distance = haversine_distance(1.3521, 103.8198, 1.2897, 103.8501)  # Ang Mo Kio to Marina Bay\n",
    "    >>> print(f\"{distance:.2f} km\")\n",
    "    7.23 km\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians (required for trigonometric functions)\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula components\n",
    "    dlat = lat2 - lat1  # Difference in latitude\n",
    "    dlon = lon2 - lon1  # Difference in longitude\n",
    "    \n",
    "    # Calculate arc length\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    \n",
    "    # Multiply by Earth's radius to get distance in kilometers\n",
    "    km = 6371 * c  # Earth's radius = 6371 km\n",
    "    return km\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTION: Get Predicted Price from ML Model\n",
    "# ============================================================================\n",
    "def get_predicted_price(flat_row, model):\n",
    "    \"\"\"\n",
    "    Predict fair market value for a single flat using the trained XGBoost model.\n",
    "    \n",
    "    This function extracts the required features from a flat record and passes them\n",
    "    to the ML model to get a predicted price. The prediction is used in the \n",
    "    value efficiency score calculation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    flat_row : pandas Series\n",
    "        A single row from the HDB dataset containing all flat features\n",
    "    model : xgboost.XGBRegressor\n",
    "        Trained XGBoost model loaded from pickle file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Predicted price in SGD\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    - Feature order MUST match the order used during model training in Section 4\n",
    "    - If you used different features or feature engineering, update this list\n",
    "    - The 16 features used here are the standard set from HDB_model_ready.csv\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> predicted_price = get_predicted_price(df.iloc[0], xgb_model)\n",
    "    >>> print(f\"Predicted: ${predicted_price:,.0f}\")\n",
    "    Predicted: $485,000\n",
    "    \"\"\"\n",
    "    # Extract features in the EXACT same order as used during training\n",
    "    # If you modified features in Section 4, update this list accordingly\n",
    "    features = flat_row[[\n",
    "        'floor_area_sqm',                           # Size of the flat\n",
    "        'lease_commence_year',                      # Year lease started (affects remaining lease)\n",
    "        'distance_to_nearest_primary_school_km',    # School proximity\n",
    "        'distance_to_nearest_high_value_school_km', # Top-tier school proximity\n",
    "        'distance_to_nearest_mrt_km',               # Public transport access\n",
    "        'distance_to_nearest_hawker_km',            # Food center proximity\n",
    "        'distance_to_nearest_mall_km',              # Shopping convenience\n",
    "        'distance_to_cbd_km',                       # Distance to Central Business District\n",
    "        'year',                                     # Transaction year\n",
    "        'month_num',                                # Transaction month (1-12)\n",
    "        'quarter',                                  # Transaction quarter (1-4)\n",
    "        'region_code',                              # Region encoding\n",
    "        'flat_type_int',                            # Flat type (1-7: 1 ROOM to MULTI-GEN)\n",
    "        'flat_model_code',                          # Flat model (0-10: Apartment, DBSS, etc.)\n",
    "        'town_code',                                # Town encoding (0-25)\n",
    "        'floor_level'                               # Floor height category\n",
    "    ]].values.reshape(1, -1)  # Reshape to 2D array (1 sample Ã— 16 features)\n",
    "    \n",
    "    # Get prediction from model\n",
    "    predicted_price = model.predict(features)[0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863631f9",
   "metadata": {},
   "source": [
    "## 4. Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SCORE 1: Travel Convenience Score (35% weight)\n",
    "# ============================================================================\n",
    "def calculate_travel_score(flat_row, destinations):\n",
    "    \"\"\"\n",
    "    Calculate travel convenience score based on weighted average distance to user destinations.\n",
    "    \n",
    "    This score prioritizes daily commutes (work) over occasional visits (parents, gym).\n",
    "    Daily destinations get 5x weight compared to weekly visits, ensuring work proximity\n",
    "    is the primary driver of location suitability.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    flat_row : pandas Series\n",
    "        Row containing flat data including coordinates (latitude, longitude)\n",
    "    destinations : list of dict\n",
    "        User-specified destinations with visit frequencies\n",
    "        Format: [\n",
    "            {'name': 'Work (CBD)', 'lat': 1.2833, 'lon': 103.8511, 'frequency': 'daily'},\n",
    "            {'name': 'Parents Home', 'lat': 1.3521, 'lon': 103.9448, 'frequency': 'weekly'},\n",
    "            ...\n",
    "        ]\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Travel score from 0-100 (higher = better location for user's travel patterns)\n",
    "        - 100: Excellent - very close to all frequent destinations\n",
    "        - 75-99: Good - reasonable commute times\n",
    "        - 50-74: Average - moderate travel distances\n",
    "        - 25-49: Poor - long commutes required\n",
    "        - 0-24: Very poor - excessive travel distances\n",
    "    \n",
    "    Algorithm:\n",
    "    ----------\n",
    "    1. Calculate distance from flat to each destination\n",
    "    2. Apply frequency weights (daily=5.0, weekly=1.0, etc.)\n",
    "    3. Compute weighted average distance\n",
    "    4. Convert to 0-100 score (lower distance = higher score)\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> destinations = [\n",
    "    ...     {'name': 'Office', 'lat': 1.28, 'lon': 103.85, 'frequency': 'daily'},  # 8km away\n",
    "    ...     {'name': 'Gym', 'lat': 1.35, 'lon': 103.87, 'frequency': '2-3_per_week'}  # 3km away\n",
    "    ... ]\n",
    "    >>> score = calculate_travel_score(flat_row, destinations)\n",
    "    >>> # Weighted avg = (8*5 + 3*2.5) / (5+2.5) = 6.33km â†’ score â‰ˆ 68/100\n",
    "    \"\"\"\n",
    "    # ========================================================================\n",
    "    # Define frequency-to-weight mapping\n",
    "    # ========================================================================\n",
    "    # These weights ensure daily commutes dominate the score\n",
    "    # A daily commute (weight=5) has same impact as 5 weekly visits (weight=1)\n",
    "    frequency_weights = {\n",
    "        'daily': 5.0,           # 5 days/week (e.g., work commute)\n",
    "        '2-3_per_week': 2.5,    # 2.5 days/week (e.g., gym, part-time work)\n",
    "        'weekly': 1.0,          # 1 day/week (e.g., visiting parents)\n",
    "        '1-2_per_month': 0.25,  # ~0.25 days/week (e.g., medical appointments)\n",
    "        'rarely': 0.05          # ~once every 3 months (e.g., rare meetups)\n",
    "    }\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Handle edge case: No destinations specified\n",
    "    # ========================================================================\n",
    "    if not destinations or len(destinations) == 0:\n",
    "        return 50  # Return neutral score if user didn't specify any destinations\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Calculate weighted average distance\n",
    "    # ========================================================================\n",
    "    total_weighted_distance = 0  # Sum of (distance Ã— weight)\n",
    "    total_weight = 0             # Sum of weights\n",
    "    \n",
    "    # TODO: Add latitude/longitude columns to your dataset if not present\n",
    "    # You may need to geocode addresses or use town centroids as approximations\n",
    "    # Example: Add 'latitude' and 'longitude' columns to HDB_model_ready.csv\n",
    "    flat_lat = flat_row.get('latitude', None)  \n",
    "    flat_lon = flat_row.get('longitude', None)\n",
    "    \n",
    "    # If coordinates missing, return neutral score\n",
    "    if flat_lat is None or flat_lon is None:\n",
    "        print(\"Warning: Flat coordinates not found. Add 'latitude' and 'longitude' columns to dataset.\")\n",
    "        return 50\n",
    "    \n",
    "    # Loop through each destination and calculate weighted distance\n",
    "    for dest in destinations:\n",
    "        # Calculate straight-line distance (Haversine formula)\n",
    "        distance = haversine_distance(flat_lat, flat_lon, dest['lat'], dest['lon'])\n",
    "        \n",
    "        # Get weight for this destination's visit frequency\n",
    "        weight = frequency_weights.get(dest['frequency'], 1.0)  # Default to 1.0 if unknown frequency\n",
    "        \n",
    "        # Accumulate weighted distance\n",
    "        total_weighted_distance += distance * weight\n",
    "        total_weight += weight\n",
    "    \n",
    "    # Calculate weighted average distance\n",
    "    weighted_avg_distance = total_weighted_distance / total_weight\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Convert distance to 0-100 score\n",
    "    # ========================================================================\n",
    "    # Assume maximum acceptable average distance is 20km\n",
    "    # 0km â†’ 100 score (perfect location)\n",
    "    # 20km+ â†’ 0 score (too far)\n",
    "    max_distance = 20  # kilometers\n",
    "    travel_score = max(0, 100 - (weighted_avg_distance / max_distance * 100))\n",
    "    \n",
    "    return round(travel_score, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d0a2a",
   "metadata": {},
   "source": [
    "## 5. Hard Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hard_filters(df, user_input):\n",
    "    \"\"\"\n",
    "    Apply hard constraints to filter candidate flats.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        Full HDB dataset\n",
    "    user_input : dict\n",
    "        User preferences from frontend\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame : Filtered candidate flats\n",
    "    \"\"\"\n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    # Budget filter (using predicted price)\n",
    "    # Note: You'll need to predict prices for all flats or filter on historical resale_price\n",
    "    if 'min_budget' in user_input and 'max_budget' in user_input:\n",
    "        # Using resale_price as proxy - in production, pre-compute predicted prices\n",
    "        filtered_df = filtered_df[\n",
    "            (filtered_df['resale_price'] >= user_input['min_budget']) &\n",
    "            (filtered_df['resale_price'] <= user_input['max_budget'])\n",
    "        ]\n",
    "    \n",
    "    # Flat type filter\n",
    "    if 'flat_types' in user_input and len(user_input['flat_types']) > 0:\n",
    "        flat_type_codes = flat_type_map[\n",
    "            flat_type_map['flat_type'].isin(user_input['flat_types'])\n",
    "        ]['flat_type_int'].tolist()\n",
    "        filtered_df = filtered_df[filtered_df['flat_type_int'].isin(flat_type_codes)]\n",
    "    \n",
    "    # Flat model filter\n",
    "    if 'flat_models' in user_input and len(user_input['flat_models']) > 0:\n",
    "        flat_model_codes = flat_model_map[\n",
    "            flat_model_map['flat_model_grouped'].isin(user_input['flat_models'])\n",
    "        ]['flat_model_code'].tolist()\n",
    "        filtered_df = filtered_df[filtered_df['flat_model_code'].isin(flat_model_codes)]\n",
    "    \n",
    "    # Floor area filter\n",
    "    if 'min_area' in user_input and 'max_area' in user_input:\n",
    "        filtered_df = filtered_df[\n",
    "            (filtered_df['floor_area_sqm'] >= user_input['min_area']) &\n",
    "            (filtered_df['floor_area_sqm'] <= user_input['max_area'])\n",
    "        ]\n",
    "    \n",
    "    # Town filter\n",
    "    if 'towns' in user_input and len(user_input['towns']) > 0:\n",
    "        town_codes = town_map[\n",
    "            town_map['town'].isin(user_input['towns'])\n",
    "        ]['town_code'].tolist()\n",
    "        filtered_df = filtered_df[filtered_df['town_code'].isin(town_codes)]\n",
    "    \n",
    "    # Lease year filter\n",
    "    if 'min_lease_year' in user_input:\n",
    "        current_year = 2025\n",
    "        remaining_lease = 99 - (current_year - filtered_df['lease_commence_year'])\n",
    "        filtered_df = filtered_df[remaining_lease >= user_input['min_lease_year']]\n",
    "    \n",
    "    # Storey filter\n",
    "    if 'storey_ranges' in user_input and len(user_input['storey_ranges']) > 0:\n",
    "        # Convert floor_level to storey ranges if needed\n",
    "        filtered_df = filtered_df[filtered_df['floor_level'].isin(user_input['storey_ranges'])]\n",
    "    \n",
    "    # Strict amenity filters (if enabled)\n",
    "    if user_input.get('strict_mrt', False) and 'max_mrt_distance' in user_input:\n",
    "        filtered_df = filtered_df[\n",
    "            filtered_df['distance_to_nearest_mrt_km'] <= user_input['max_mrt_distance']\n",
    "        ]\n",
    "    \n",
    "    if user_input.get('strict_mall', False) and 'max_mall_distance' in user_input:\n",
    "        filtered_df = filtered_df[\n",
    "            filtered_df['distance_to_nearest_mall_km'] <= user_input['max_mall_distance']\n",
    "        ]\n",
    "    \n",
    "    if user_input.get('strict_school', False) and 'max_school_distance' in user_input:\n",
    "        filtered_df = filtered_df[\n",
    "            filtered_df['distance_to_nearest_primary_school_km'] <= user_input['max_school_distance']\n",
    "        ]\n",
    "    \n",
    "    print(f\"Candidates after filtering: {len(filtered_df)}\")\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d49b707",
   "metadata": {},
   "source": [
    "## 6. Main Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(user_input, top_n=10):\n",
    "    \"\"\"\n",
    "    Main function to generate flat recommendations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    user_input : dict\n",
    "        User preferences from frontend JSON\n",
    "    top_n : int\n",
    "        Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : Top N recommended flats with scores\n",
    "    \"\"\"\n",
    "    # Step 1: Apply hard filters\n",
    "    candidates_df = apply_hard_filters(df, user_input)\n",
    "    \n",
    "    if len(candidates_df) == 0:\n",
    "        return {'error': 'No flats match your criteria. Please relax some filters.'}\n",
    "    \n",
    "    # Step 2: Get predicted prices for all candidates\n",
    "    print(\"Calculating predicted prices...\")\n",
    "    candidates_df['predicted_price'] = candidates_df.apply(\n",
    "        lambda row: get_predicted_price(row, xgb_model), axis=1\n",
    "    )\n",
    "    candidates_df['predicted_price_per_sqm'] = (\n",
    "        candidates_df['predicted_price'] / candidates_df['floor_area_sqm']\n",
    "    )\n",
    "    \n",
    "    # Step 3: Calculate all scores\n",
    "    print(\"Calculating scores...\")\n",
    "    results = []\n",
    "    \n",
    "    for idx, row in candidates_df.iterrows():\n",
    "        # Calculate individual scores\n",
    "        travel_score = calculate_travel_score(row, user_input.get('destinations', []))\n",
    "        value_score = calculate_value_score(row, row['predicted_price'], candidates_df)\n",
    "        budget_score = calculate_budget_score(\n",
    "            row['predicted_price'], \n",
    "            user_input['min_budget'], \n",
    "            user_input['max_budget']\n",
    "        )\n",
    "        amenity_score = calculate_amenity_score(row)\n",
    "        space_score = calculate_space_score(\n",
    "            row['floor_area_sqm'],\n",
    "            user_input.get('min_area', 0),\n",
    "            user_input.get('max_area', 200)\n",
    "        )\n",
    "        \n",
    "        # Calculate weighted final score\n",
    "        final_score = (\n",
    "            0.35 * travel_score +\n",
    "            0.25 * value_score +\n",
    "            0.20 * budget_score +\n",
    "            0.15 * amenity_score +\n",
    "            0.05 * space_score\n",
    "        )\n",
    "        \n",
    "        # Get town name\n",
    "        town_name = town_map[\n",
    "            town_map['town_code'] == row['town_code']\n",
    "        ]['town'].values[0] if len(town_map[town_map['town_code'] == row['town_code']]) > 0 else 'Unknown'\n",
    "        \n",
    "        # Get flat type name\n",
    "        flat_type_name = flat_type_map[\n",
    "            flat_type_map['flat_type_int'] == row['flat_type_int']\n",
    "        ]['flat_type'].values[0] if len(flat_type_map[flat_type_map['flat_type_int'] == row['flat_type_int']]) > 0 else 'Unknown'\n",
    "        \n",
    "        # Store result\n",
    "        results.append({\n",
    "            'flat_id': idx,\n",
    "            'town': town_name,\n",
    "            'flat_type': flat_type_name,\n",
    "            'floor_area_sqm': float(row['floor_area_sqm']),\n",
    "            'predicted_price': float(row['predicted_price']),\n",
    "            'lease_commence_year': int(row['lease_commence_year']),\n",
    "            'floor_level': int(row['floor_level']),\n",
    "            'scores': {\n",
    "                'travel_score': float(travel_score),\n",
    "                'value_score': float(value_score),\n",
    "                'budget_score': float(budget_score),\n",
    "                'amenity_score': float(amenity_score),\n",
    "                'space_score': float(space_score),\n",
    "                'final_score': float(round(final_score, 2))\n",
    "            },\n",
    "            'distances': {\n",
    "                'mrt_km': float(row['distance_to_nearest_mrt_km']),\n",
    "                'school_km': float(row['distance_to_nearest_primary_school_km']),\n",
    "                'mall_km': float(row['distance_to_nearest_mall_km']),\n",
    "                'hawker_km': float(row['distance_to_nearest_hawker_km']),\n",
    "                'cbd_km': float(row['distance_to_cbd_km'])\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Step 4: Sort by final score and return top N\n",
    "    results_sorted = sorted(results, key=lambda x: x['scores']['final_score'], reverse=True)\n",
    "    \n",
    "    return {\n",
    "        'total_candidates': len(candidates_df),\n",
    "        'recommendations': results_sorted[:top_n]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a5685",
   "metadata": {},
   "source": [
    "## 7. Test with Sample Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4192d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample user input (matches what your React frontend will send)\n",
    "sample_user_input = {\n",
    "    'min_budget': 400000,\n",
    "    'max_budget': 600000,\n",
    "    'flat_types': ['4 ROOM', '5 ROOM'],\n",
    "    'flat_models': ['Improved', 'Model A', 'New Generation'],\n",
    "    'min_area': 80,\n",
    "    'max_area': 110,\n",
    "    'towns': ['BISHAN', 'ANG MO KIO', 'TOA PAYOH'],\n",
    "    'min_lease_year': 70,\n",
    "    'destinations': [\n",
    "        {'name': 'CBD', 'lat': 1.2833, 'lon': 103.8511, 'frequency': 'daily'},\n",
    "        {'name': 'Jurong East', 'lat': 1.3330, 'lon': 103.7436, 'frequency': 'daily'},\n",
    "        {'name': 'Parents Home', 'lat': 1.3521, 'lon': 103.9448, 'frequency': 'weekly'}\n",
    "    ],\n",
    "    'strict_mrt': False,\n",
    "    'max_mrt_distance': 1.0,\n",
    "    'strict_mall': False,\n",
    "    'max_mall_distance': 1.5\n",
    "}\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations = generate_recommendations(sample_user_input, top_n=10)\n",
    "\n",
    "# Display results\n",
    "print(json.dumps(recommendations, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5376c",
   "metadata": {},
   "source": [
    "## 8. Flask API Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd780ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as a separate file: app.py\n",
    "\n",
    "\"\"\"\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for React frontend\n",
    "\n",
    "# Load data and model at startup\n",
    "df = pd.read_csv('path/to/HDB_model_ready.csv')\n",
    "town_map = pd.read_csv('path/to/town_code_map.csv')\n",
    "flat_type_map = pd.read_csv('path/to/flat_type_int_map.csv')\n",
    "flat_model_map = pd.read_csv('path/to/flat_model_code_map.csv')\n",
    "\n",
    "with open('path/to/xgboost_model.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)\n",
    "\n",
    "# Include all the scoring functions here (copy from above cells)\n",
    "\n",
    "@app.route('/api/recommend', methods=['POST'])\n",
    "def recommend():\n",
    "    try:\n",
    "        user_input = request.json\n",
    "        \n",
    "        # Validate input\n",
    "        if 'min_budget' not in user_input or 'max_budget' not in user_input:\n",
    "            return jsonify({'error': 'Budget range is required'}), 400\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommendations = generate_recommendations(user_input, top_n=10)\n",
    "        \n",
    "        return jsonify(recommendations)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "\n",
    "@app.route('/api/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({'status': 'healthy', 'total_flats': len(df)})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Flask API code above - save as app.py\")\n",
    "print(\"\\nTo run: python app.py\")\n",
    "print(\"API will be available at: http://localhost:5000/api/recommend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3745ed",
   "metadata": {},
   "source": [
    "## 9. Frontend Integration Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8845f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example React frontend code to call your API\n",
    "\n",
    "\"\"\"\n",
    "// In your React component:\n",
    "\n",
    "const getRecommendations = async (userPreferences) => {\n",
    "  try {\n",
    "    const response = await fetch('http://localhost:5000/api/recommend', {\n",
    "      method: 'POST',\n",
    "      headers: {\n",
    "        'Content-Type': 'application/json',\n",
    "      },\n",
    "      body: JSON.stringify(userPreferences)\n",
    "    });\n",
    "    \n",
    "    const data = await response.json();\n",
    "    \n",
    "    if (data.error) {\n",
    "      console.error('Error:', data.error);\n",
    "      return;\n",
    "    }\n",
    "    \n",
    "    // Display recommendations\n",
    "    console.log('Total candidates:', data.total_candidates);\n",
    "    console.log('Top recommendations:', data.recommendations);\n",
    "    \n",
    "    // Update your UI state\n",
    "    setRecommendations(data.recommendations);\n",
    "    \n",
    "  } catch (error) {\n",
    "    console.error('API call failed:', error);\n",
    "  }\n",
    "};\n",
    "\n",
    "// Call when user submits the form\n",
    "const handleSubmit = (formData) => {\n",
    "  const userPreferences = {\n",
    "    min_budget: formData.minBudget,\n",
    "    max_budget: formData.maxBudget,\n",
    "    flat_types: formData.selectedFlatTypes,\n",
    "    flat_models: formData.selectedModels,\n",
    "    towns: formData.selectedTowns,\n",
    "    destinations: formData.destinations,\n",
    "    // ... other fields\n",
    "  };\n",
    "  \n",
    "  getRecommendations(userPreferences);\n",
    "};\n",
    "\"\"\"\n",
    "\n",
    "print(\"React integration example above\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
